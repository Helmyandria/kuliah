{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What will we learn?\n",
    "===================\n",
    "\n",
    "* Introduction to information retrieval\n",
    "* Text Analysis and Preprocessing\n",
    "* Text Retrieval\n",
    "* Vector Space Model\n",
    "* Probabilistic Model\n",
    "* Query Expansion and Feedback\n",
    "* Text Filtering\n",
    "* Text Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL To the fullest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<?php\n",
    "$keyword = isset($_GET['keyword'])? $_GET['keyword'] : 'Bunga matahari';\n",
    "$keyword = trim($keyword);\n",
    "$keyword_list = explode(' ', $keyword);\n",
    "$delimiters = array(' ', '-');\n",
    "$where_list = [];\n",
    "foreach($keyword_list as $word){\n",
    "    $or_list = array();\n",
    "    foreach($delimiters as $delimiter_word){\n",
    "        $or_list[] = \" artikel LIKE '%\".$delimiter_word.$word.\"'\";\n",
    "        $or_list[] = \" artikel LIKE '\".$word.$delimiter_word.\"%'\";\n",
    "        foreach($delimiters as $other_delimiter_word){\n",
    "            $or_list[] = \" artikel LIKE '%\".$delimiter_word.$word.$other_delimiter_word.\"%'\";\n",
    "        }\n",
    "    }\n",
    "    $where_list[] = '(' . implode(PHP_EOL.' OR ', $or_list) . ')';\n",
    "}\n",
    "$where = implode(PHP_EOL.' AND ', $where_list);\n",
    "\n",
    "$sql = \"SELECT id, artikel FROM artikel where $where\";\n",
    "// Tampilkan keyword\n",
    "echo 'Keyword : ' . $keyword . '<br />';\n",
    "// Jalanin sql dan tampilin\n",
    "$conn = mysqli_connect('localhost', 'root', 'toor', 'information_retrieval');\n",
    "$query = mysqli_query($conn, $sql);\n",
    "while($row = mysqli_fetch_array($query)){\n",
    "    echo $row['id'] . ' ' . $row['artikel'];\n",
    "    echo '<br />';\n",
    "}\n",
    "// Tampilin SQL\n",
    "var_dump($sql);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "['hari', 'minggu', 'saya', 'pergi', 'pasar', 'malam', 'ada', 'diskon', 'besar', 'dapat', 'banyak', 'main', 'jadi', 'bakar', 'buat']\n",
      "\n",
      "Pada hari minggu saya pergi ke pasar malam malam\n",
      "[1, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Malam itu di pasar ada diskon besar besaran\n",
      "[0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0]\n",
      "Di pasar malam terdapat banyak permainan\n",
      "[0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0]\n",
      "Malam minggu di pasar terjadi kebakaran\n",
      "[0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "Ada mainan terbuat dari malam\n",
      "[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "\n",
      "Pasar Malam Minggu\n",
      "[0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "articles = [\n",
    "   'Pada hari minggu saya pergi ke pasar malam malam',\n",
    "   'Malam itu di pasar ada diskon besar besaran',\n",
    "   'Di pasar malam terdapat banyak permainan',\n",
    "   'Malam minggu di pasar terjadi kebakaran',\n",
    "   'Ada mainan terbuat dari malam'\n",
    "]\n",
    "\n",
    "unique_words = []\n",
    "stem = {\n",
    "    'besaran' : 'besar',\n",
    "    'mainan'  : 'main',\n",
    "    'permainan' : 'main',\n",
    "    'kebakaran' : 'bakar',\n",
    "    'terjadi'   : 'jadi',\n",
    "    'terbuat'   : 'buat',\n",
    "    'terdapat'  : 'dapat',\n",
    "    'di'        : '',\n",
    "    'dan'       : '',\n",
    "    'ke'        : '',\n",
    "    'dari'      : '',\n",
    "    'pada'      : '',\n",
    "    'itu'       : '',\n",
    "}\n",
    "for article in articles:\n",
    "    words = article.split(' ')\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        for key in stem:\n",
    "            if word == key:\n",
    "                word = stem[key]\n",
    "        if word == '':\n",
    "            continue\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "print len(unique_words)\n",
    "print unique_words\n",
    "\n",
    "def vectorize(articles):\n",
    "    vectors = []\n",
    "    for article in articles:\n",
    "        vector = []\n",
    "        for i in range(len(unique_words)):\n",
    "            vector.append(0)\n",
    "        words = article.split(' ')\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            for key in stem:\n",
    "                if word == key:\n",
    "                    word = stem[key]\n",
    "            if word == '':\n",
    "                continue\n",
    "            for i, unique_word in enumerate(unique_words):\n",
    "                if unique_word == word:\n",
    "                    vector[i] += 1\n",
    "                    break\n",
    "        vectors.append(vector)\n",
    "    return vectors\n",
    "\n",
    "vectors = vectorize(articles)\n",
    "print \"\"\n",
    "for i, article in enumerate(articles):\n",
    "    print article\n",
    "    print vectors[i]\n",
    "\n",
    "keyword = 'Pasar Malam Minggu'\n",
    "keyword_vector = vectorize([keyword])[0]\n",
    "print \"\"\n",
    "print keyword\n",
    "print keyword_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector\n",
    "======\n",
    "\n",
    "$$ a=\n",
    "\\begin{bmatrix}\n",
    "    a_{x} \\\\\n",
    "    a_{y} \\\\\n",
    "    a_{z} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$|a| = \\sqrt{a_x^2 + b_x^2}$$\n",
    "\n",
    "Dot product?\n",
    "============\n",
    "$$a \\cdot b = |a| \\times |b| \\cos(\\theta) $$\n",
    "\n",
    "and\n",
    "\n",
    "$$a \\cdot b = (a_x \\times b_x) + (a_y \\times b_y) $$\n",
    "\n",
    "Therefore\n",
    "=========\n",
    "$$\\cos(\\theta) = \\frac{(a_x \\times b_x) + (a_y \\times b_y)}{|a| \\times |b|}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pada hari minggu saya pergi ke pasar malam malam\n",
      "[1, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.692268011609\n",
      "\n",
      "Malam itu di pasar ada diskon besar besaran\n",
      "[0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0]\n",
      "1.15026199151\n",
      "\n",
      "Di pasar malam terdapat banyak permainan\n",
      "[0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0]\n",
      "1.02815722455\n",
      "\n",
      "Malam minggu di pasar terjadi kebakaran\n",
      "[0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "0.684719203002\n",
      "\n",
      "Ada mainan terbuat dari malam\n",
      "[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "1.27795355507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def length(vector):\n",
    "    cummulation = 0\n",
    "    for number in vector:\n",
    "        cummulation += number * number\n",
    "    return cummulation ** 0.5\n",
    "\n",
    "def dot_product(vector_1, vector_2):\n",
    "    cummulation = 0\n",
    "    for i, num_1 in enumerate(vector_1):\n",
    "        num_2 = vector_2[i]\n",
    "        cummulation += num_1 * num_2\n",
    "    return cummulation\n",
    "\n",
    "def cos_theta(vector_1, vector_2):\n",
    "    return dot_product(vector_1, vector_2)/(length(vector_1) * length(vector_2))\n",
    "\n",
    "def theta_value(vector_1, vector_2):\n",
    "    return math.acos(cos_theta(vector_1, vector_2))\n",
    "\n",
    "for i, article in enumerate(articles):\n",
    "    vector = vectors[i]\n",
    "    theta = theta_value(vector, keyword_vector)\n",
    "    print article\n",
    "    print vector\n",
    "    print theta\n",
    "    print ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VSM, Exercise\n",
    "\n",
    "## Terdapat tiga buah artikel\n",
    "\n",
    "* Sistem operasi adalah komponen pengolah piranti lunak dasar tersistem sebagai pengelola sumber daya perangkat keras komputer, dan menyediakan layanan umum untuk aplikasi perangkat lunak.\n",
    "\n",
    "* Piranti lunak dasar untuk mengelola sumber daya perangkat keras dan menyediakan layanan umum untuk perangkat lunak lain disebut sistem operasi\n",
    "\n",
    "* Drum adalah piranti musik yang terdiri dari beberapa bagian. Dan dari masing-masing bagian tersebut mempunyai peran tersendiri.\n",
    "\n",
    "## Terdapat sebuah keyword\n",
    "\n",
    "* Aplikasi piranti musik digital \n",
    "\n",
    "## Tentukan\n",
    "\n",
    "* Kata-kata unik yang ada pada semua artikel & keyword\n",
    "* Hitung panjang vektor untuk setiap artikel dan keyword\n",
    "* Similarity antara keyword dengan artikel pertama, kedua, dan ketiga\n",
    "* Similarity antara artikel pertama dengan:\n",
    "    * Artikel kedua\n",
    "    * Artikel ketiga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean indexing\n",
    "\n",
    "* Find unique words in all articles\n",
    "* Make a matrix consists of the existance of the unique words in each character\n",
    "\n",
    "# Boolean retrieval\n",
    "\n",
    "* Perform boolean operation of the keywords\n",
    "\n",
    "# Code example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kata-kata unik: \n",
      "['hari', 'minggu', 'saya', 'pergi', 'pasar', 'malam', 'ada', 'diskon', 'besar', 'dapat', 'banyak', 'main', 'jadi', 'bakar', 'buat']\n",
      "\n",
      "Jumlah kata-kata unik: 15\n"
     ]
    }
   ],
   "source": [
    "def get_unique_words(articles):\n",
    "    unique_words = []\n",
    "    stem = {\n",
    "        'besaran' : 'besar',\n",
    "        'mainan'  : 'main',\n",
    "        'permainan' : 'main',\n",
    "        'kebakaran' : 'bakar',\n",
    "        'terjadi'   : 'jadi',\n",
    "        'terbuat'   : 'buat',\n",
    "        'terdapat'  : 'dapat',\n",
    "        'di'        : '',\n",
    "        'dan'       : '',\n",
    "        'ke'        : '',\n",
    "        'dari'      : '',\n",
    "        'pada'      : '',\n",
    "        'itu'       : '',\n",
    "    }\n",
    "    for article in articles:\n",
    "        words = article.split(' ')\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            for key in stem:\n",
    "                if word == key:\n",
    "                    word = stem[key]\n",
    "            if word == '':\n",
    "                continue\n",
    "            if word not in unique_words:\n",
    "                unique_words.append(word)\n",
    "    return unique_words\n",
    "\n",
    "def AND(array1, array2):\n",
    "    result = []\n",
    "    for i in range(len(array1)):\n",
    "        result.append(array1[i] and array2[i])\n",
    "    return result\n",
    "\n",
    "def OR(array1, array2):\n",
    "    result = []\n",
    "    for i in range(len(array1)):\n",
    "        result.append(array1[i] or array2[i])\n",
    "    return result\n",
    "\n",
    "def NOT(array):\n",
    "    result = []\n",
    "    for i in range(len(array)):\n",
    "        result.append(not array[i])\n",
    "    return result\n",
    "\n",
    "articles = [\n",
    "   'Pada hari minggu saya pergi ke pasar malam malam',\n",
    "   'Malam itu di pasar ada diskon besar besaran',\n",
    "   'Di pasar malam terdapat banyak permainan',\n",
    "   'Malam minggu di pasar terjadi kebakaran',\n",
    "   'Ada mainan terbuat dari malam'\n",
    "]\n",
    "unique_words = get_unique_words(articles)\n",
    "print \"Kata-kata unik: \"\n",
    "print unique_words\n",
    "print \"\"\n",
    "print \"Jumlah kata-kata unik: \" + str(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pada hari minggu saya pergi ke pasar malam malam\n",
      "Malam itu di pasar ada diskon besar besaran\n",
      "Di pasar malam terdapat banyak permainan\n",
      "Malam minggu di pasar terjadi kebakaran\n",
      "Ada mainan terbuat dari malam\n",
      "\n",
      "BOOLEAN INDEX:\n",
      "hari [True, False, False, False, False]\n",
      "minggu [True, False, False, True, False]\n",
      "saya [True, False, False, False, False]\n",
      "pergi [True, False, False, False, False]\n",
      "pasar [True, True, True, True, False]\n",
      "malam [True, True, True, True, True]\n",
      "ada [False, True, False, False, True]\n",
      "diskon [False, True, False, False, False]\n",
      "besar [False, True, False, False, False]\n",
      "dapat [False, False, True, False, False]\n",
      "banyak [False, False, True, False, False]\n",
      "main [False, False, True, False, True]\n",
      "jadi [False, False, False, True, False]\n",
      "bakar [False, False, False, True, False]\n",
      "buat [False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "stem = {\n",
    "    'besaran' : 'besar',\n",
    "    'mainan'  : 'main',\n",
    "    'permainan' : 'main',\n",
    "    'kebakaran' : 'bakar',\n",
    "    'terjadi'   : 'jadi',\n",
    "    'terbuat'   : 'buat',\n",
    "    'terdapat'  : 'dapat',\n",
    "    'di'        : '',\n",
    "    'dan'       : '',\n",
    "    'ke'        : '',\n",
    "    'dari'      : '',\n",
    "    'pada'      : '',\n",
    "    'itu'       : '',\n",
    "}\n",
    "boolean_indexes = []\n",
    "for unique_word in unique_words:\n",
    "    boolean_index = []\n",
    "    for article in articles:\n",
    "        found = False\n",
    "        words = article.split(' ')\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            for key in stem:\n",
    "                if word == key:\n",
    "                    word = stem[key]\n",
    "            if word == '':\n",
    "                continue\n",
    "            if word == unique_word:\n",
    "                found = True\n",
    "                break\n",
    "        boolean_index.append(found)\n",
    "    boolean_indexes.append(boolean_index)\n",
    "    \n",
    "for article in articles:\n",
    "    print article\n",
    "print \"\\nBOOLEAN INDEX:\"\n",
    "for i, unique_word in enumerate(unique_words):\n",
    "    print unique_word + \" \" + str(boolean_indexes[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result : \n",
      "[False, True, True, True, False]\n",
      "Malam itu di pasar ada diskon besar besaran\n",
      "Di pasar malam terdapat banyak permainan\n",
      "Malam minggu di pasar terjadi kebakaran\n"
     ]
    }
   ],
   "source": [
    "# (malam AND NOT diskon) OR bakar\n",
    "\n",
    "def find_boolean_index(word):\n",
    "    for i, unique_word in enumerate(unique_words):\n",
    "        if word == unique_word:\n",
    "            return boolean_indexes[i]\n",
    "\n",
    "malam = find_boolean_index('malam')\n",
    "diskon = find_boolean_index('diskon')\n",
    "bakar = find_boolean_index('bakar')\n",
    "minggu = find_boolean_index('minggu')\n",
    "pasar = find_boolean_index('pasar')\n",
    "\n",
    "result = OR(bakar, AND(pasar, NOT(minggu)) )\n",
    "print \"Result : \"\n",
    "print result\n",
    "for i, article in enumerate(articles):\n",
    "    if result[i]:\n",
    "        print article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The term vocabulary and postings lists\n",
    "\n",
    "* Collect the documents to be indexed. [http://www.crummy.com/software/BeautifulSoup/bs4/doc/](http://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "\n",
    "    - Is it a webpage?\n",
    "    - Ascii character?\n",
    "    - Unicode (hangul, kanji, hiragana, katakana, arabic?)\n",
    "    \n",
    "    \n",
    "* Tokenize the text. [http://text-processing.com/demo/tokenize/](http://text-processing.com/demo/tokenize/), [http://sastrawi.github.io/tokenizer.html](http://sastrawi.github.io/tokenizer.html)\n",
    "\n",
    "    - Chop your documents into words\n",
    "    \n",
    "    \n",
    "* Do linguistic preprocessing of tokens.\n",
    "\n",
    "    - stemming\n",
    "    - lematization\n",
    "    \n",
    "    \n",
    "* Index the documents that each term occurs in.\n",
    "\n",
    "\n",
    "## Porter Algorithm\n",
    "Rule\n",
    "* `SSES -> SS`, \n",
    "\n",
    "    E.g: caresses -> caress\n",
    "    \n",
    "    \n",
    "* `IES -> I`, \n",
    "\n",
    "    E.g: ponies -> poni\n",
    "    \n",
    "    \n",
    "* `SS --> SS`, \n",
    "\n",
    "    E.g: caress -> caress\n",
    "    \n",
    "    \n",
    "* `S --> (ommited)`, \n",
    "\n",
    "    E.g: cats -> cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENS : =======\n",
      "['My', 'cats', 'losses', 'all', 'of', 'his', 'fur', 'because', 'he', 'messes', 'around', 'with', 'some', 'ponies']\n",
      "APPLY PORTER ALGORITHMS : =====\n",
      "['my', 'cat', 'loss', 'all', 'of', 'hi', 'fur', 'because', 'he', 'mess', 'around', 'with', 'some', 'poni']\n"
     ]
    }
   ],
   "source": [
    "article = \"My cats losses all of his fur because he messes around with some ponies\"\n",
    "tokens = article.split(' ')\n",
    "print \"TOKENS : =======\"\n",
    "print tokens\n",
    "\n",
    "print \"APPLY PORTER ALGORITHMS : =====\"\n",
    "rule_indexes = ['sses', 'ies', 'ss', 's']\n",
    "rules = {\n",
    "    'sses' : 'ss',\n",
    "    'ies'  : 'i',\n",
    "    'ss'   : 'ss',\n",
    "    's'    : ''\n",
    "}\n",
    "for i, token in enumerate(tokens):\n",
    "    token = token.lower()\n",
    "    for rule in rule_indexes:\n",
    "        suffix = token[-len(rule):]\n",
    "        if suffix == rule:\n",
    "            token = token[:-len(rule)] + rules[rule]\n",
    "            break\n",
    "    tokens[i] = token\n",
    "print tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "\n",
    "* Term Frequency: How often a term occured in a document $${tf}_{t,d}$$\n",
    "* Document Frequency: How many documents contains specific term $${df}_{t}$$\n",
    "* Inverse Document Frequency: $$idf_{t} = \\log{\\frac{N}{df_{t}}}$$\n",
    "\n",
    "  where $N$ is count of documents\n",
    "  \n",
    "* Weight (tf.idf): $$w_{t,d} = tf_{t,d}\\times idf_{t}$$\n",
    "\n",
    "![PR.png](PR.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w [harga][D1] = 6.0\n",
      "w [harga][D2] = 14.0\n",
      "w [harga][D3] = 2.0\n",
      "w [harga][D4] = 12.0\n",
      "w [saham][D1] = 3.97940008672\n",
      "w [saham][D2] = 0.0\n",
      "w [saham][D3] = 1.59176003469\n",
      "w [saham][D4] = 0.0\n",
      "w [dunia][D1] = 2.09691001301\n",
      "w [dunia][D2] = 1.39794000867\n",
      "w [dunia][D3] = 4.89279003035\n",
      "w [dunia][D4] = 1.39794000867\n",
      "w [turun][D1] = 0.0\n",
      "w [turun][D2] = 5.20411998266\n",
      "w [turun][D3] = 7.80617997398\n",
      "w [turun][D4] = 9.10720996965\n",
      "w [investor][D1] = 5.0\n",
      "w [investor][D2] = 3.0\n",
      "w [investor][D3] = 2.0\n",
      "w [investor][D4] = 1.0\n",
      "w [rugi][D1] = 15.290730039\n",
      "w [rugi][D2] = 0.0\n",
      "w [rugi][D3] = 10.193820026\n",
      "w [rugi][D4] = 3.39794000867\n"
     ]
    }
   ],
   "source": [
    "daftar_kata    = ['harga', 'saham', 'dunia', 'turun', 'investor', 'rugi']\n",
    "daftar_dokumen = ['D1', 'D2', 'D3', 'D4']\n",
    "#jumlah kata tertentu pada dokumen tertentu\n",
    "tf = {\n",
    "    'harga'    :{'D1' :  3, 'D2' :  7, 'D3' :  1, 'D4' :  6},\n",
    "    'saham'    :{'D1' : 10, 'D2' :  0, 'D3' :  4, 'D4' :  0},\n",
    "    'dunia'    :{'D1' :  3, 'D2' :  2, 'D3' :  7, 'D4' :  2},\n",
    "    'turun'    :{'D1' :  0, 'D2' :  4, 'D3' :  6, 'D4' :  7},\n",
    "    'investor' :{'D1' :  5, 'D2' :  3, 'D3' :  2, 'D4' :  1},\n",
    "    'rugi'     :{'D1' :  9, 'D2' :  0, 'D3' :  6, 'D4' :  2}\n",
    "}\n",
    "# jumlah dokumen yang mengandung kata tertentu\n",
    "df = {\n",
    "    'harga'    :  100,\n",
    "    'saham'    : 4000,\n",
    "    'dunia'    : 2000,\n",
    "    'turun'    :  500,\n",
    "    'investor' : 1000,\n",
    "    'rugi'     :  200\n",
    "}\n",
    "# jumlah dokumen\n",
    "N  = 10000.0\n",
    "\n",
    "# hitung idf\n",
    "import math\n",
    "idf = {}\n",
    "for kata in daftar_kata:\n",
    "    idf[kata] = math.log(N/df[kata], 10) # log di python by default berbasis 2\n",
    "\n",
    "# hitung w\n",
    "w = {}\n",
    "for kata in daftar_kata:\n",
    "    w[kata] = {}\n",
    "    for dokumen in daftar_dokumen:\n",
    "        w[kata][dokumen] = tf[kata][dokumen] * idf[kata]\n",
    "        print 'w [' + kata + '][' + dokumen + '] = ' + str(w[kata][dokumen])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model in IR\n",
    "\n",
    "$$[D, F, Q, R(q, d_j )]$$\n",
    "\n",
    "Where\n",
    "\n",
    "* $D$ : Set of documents\n",
    "* $F$ : Model (e.g: boolean, Vector Space)\n",
    "* $Q$ : Set of query\n",
    "* $R(q, d_j)$ : Ranking function, $q \\in Q$ and $d_j \\in D$\n",
    "\n",
    "## Boolean Model\n",
    "\n",
    "* Boolean Indexing\n",
    "* Boolean Retrieval\n",
    "\n",
    "## Boolean Ranking Function\n",
    "\n",
    "Supposed a document consists of two parts, `title` and `content`. The `title` part is considered to be more important than `content` (e.g: Google SEO)\n",
    "\n",
    "$$score(d,q) = w \\times S_t(q,d) + (1-w) \\times S_b(q,d) $$\n",
    "\n",
    "where $w$ is the weight of `title`. The value should be between `0` and `1`\n",
    "\n",
    "## Vector Space Model\n",
    "\n",
    "* Geometric model \n",
    "* Each documents are vectors and each words are dimensions\n",
    "\n",
    "## Vector Space Model Ranking Function\n",
    "\n",
    "1. Cosine Similarity: $\\cos(\\theta) = \\frac{(a_x \\times b_x) + (a_y \\times b_y)}{|a| \\times |b|}$\n",
    "2. Dot product Similarity : $sim(d_j, q) = d_j \\cdot q$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['94', '94%', '98', '96', '100', '97', '83']\n"
     ]
    }
   ],
   "source": [
    "# http://www.rottentomatoes.com/tv/game-of-thrones/?search=Game%20of%20Thrones\n",
    "\n",
    "from lxml import html\n",
    "import requests\n",
    "\n",
    "page = requests.get('http://www.rottentomatoes.com/tv/game-of-thrones/?search=Game%20of%20Thrones')\n",
    "tree = html.fromstring(page.content)\n",
    "\n",
    "rating = tree.xpath('//span[@itemprop=\"ratingValue\"]/text()')\n",
    "\n",
    "print rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shawshank Redemption\n",
      "Cast : Frank Darabont (dir.), Tim Robbins, Morgan Freeman\n",
      "Link : http://www.imdb.com//title/tt0111161/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=2239792642&pf_rd_r=15GYW03E6VWGJ7K315H3&pf_rd_s=center-1&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_tt_1\n",
      "['\\nTwo imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.']\n",
      "\n",
      "The Godfather\n",
      "Cast : Francis Ford Coppola (dir.), Marlon Brando, Al Pacino\n",
      "Link : http://www.imdb.com//title/tt0068646/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=2239792642&pf_rd_r=15GYW03E6VWGJ7K315H3&pf_rd_s=center-1&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_tt_2\n",
      "['\\nThe aging patriarch of an organized crime dynasty transfers control of his clandestine empire to his reluctant son.']\n",
      "\n",
      "The Godfather: Part II\n",
      "Cast : Francis Ford Coppola (dir.), Al Pacino, Robert De Niro\n",
      "Link : http://www.imdb.com//title/tt0071562/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=2239792642&pf_rd_r=15GYW03E6VWGJ7K315H3&pf_rd_s=center-1&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_tt_3\n",
      "['\\nThe early life and career of Vito Corleone in 1920s New York is portrayed while his son, Michael, expands and tightens his grip on his crime syndicate stretching from Lake Tahoe, Nevada to pre-revolution 1958 Cuba.']\n",
      "\n",
      "The Dark Knight\n",
      "Cast : Christopher Nolan (dir.), Christian Bale, Heath Ledger\n",
      "Link : http://www.imdb.com//title/tt0468569/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=2239792642&pf_rd_r=15GYW03E6VWGJ7K315H3&pf_rd_s=center-1&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_tt_4\n",
      "['\\nWhen the menace known as the Joker wreaks havoc and chaos on the people of Gotham, the caped crusader must come to terms with one of the greatest psychological tests of his ability to fight injustice.']\n",
      "\n",
      "12 Angry Men\n",
      "Cast : Sidney Lumet (dir.), Henry Fonda, Lee J. Cobb\n",
      "Link : http://www.imdb.com//title/tt0050083/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=2239792642&pf_rd_r=15GYW03E6VWGJ7K315H3&pf_rd_s=center-1&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_tt_5\n",
      "['\\nA dissenting juror in a murder trial slowly manages to convince the others that the case is not as obviously clear as it seemed in court.']\n",
      "\n",
      "Schindler's List\n",
      "Cast : Steven Spielberg (dir.), Liam Neeson, Ralph Fiennes\n",
      "Link : http://www.imdb.com//title/tt0108052/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=2239792642&pf_rd_r=15GYW03E6VWGJ7K315H3&pf_rd_s=center-1&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_tt_6\n",
      "['\\nIn Poland during World War II, Oskar Schindler gradually becomes concerned for his Jewish workforce after witnessing their persecution by the Nazis.']\n",
      "\n",
      "Pulp Fiction\n",
      "Cast : Quentin Tarantino (dir.), John Travolta, Uma Thurman\n",
      "Link : http://www.imdb.com//title/tt0110912/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=2239792642&pf_rd_r=15GYW03E6VWGJ7K315H3&pf_rd_s=center-1&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_tt_7\n",
      "[\"\\nThe lives of two mob hit men, a boxer, a gangster's wife, and a pair of diner bandits intertwine in four tales of violence and redemption.\"]\n",
      "\n",
      "Il buono, il brutto, il cattivo\n",
      "Cast : Sergio Leone (dir.), Clint Eastwood, Eli Wallach\n",
      "Link : http://www.imdb.com//title/tt0060196/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=2239792642&pf_rd_r=15GYW03E6VWGJ7K315H3&pf_rd_s=center-1&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_tt_8\n",
      "['\\nA bounty hunting scam joins two men in an uneasy alliance against a third in a race to find a fortune in gold buried in a remote cemetery.']\n",
      "\n",
      "The Lord of the Rings: The Return of the King\n",
      "Cast : Peter Jackson (dir.), Elijah Wood, Viggo Mortensen\n",
      "Link : http://www.imdb.com//title/tt0167260/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=2239792642&pf_rd_r=15GYW03E6VWGJ7K315H3&pf_rd_s=center-1&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_tt_9\n",
      "[\"\\nGandalf and Aragorn lead the World of Men against Sauron's army to draw his gaze from Frodo and Sam as they approach Mount Doom with the One Ring.\"]\n",
      "\n",
      "Fight Club\n",
      "Cast : David Fincher (dir.), Brad Pitt, Edward Norton\n",
      "Link : http://www.imdb.com//title/tt0137523/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=2239792642&pf_rd_r=15GYW03E6VWGJ7K315H3&pf_rd_s=center-1&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_tt_10\n",
      "['\\nAn insomniac office worker, looking for a way to change his life, crosses paths with a devil-may-care soap maker, forming an underground fight club that evolves into something much, much more...']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# http://www.imdb.com/chart/top\n",
    "from lxml import html\n",
    "import requests\n",
    "\n",
    "page = requests.get('http://www.imdb.com/chart/top')\n",
    "tree = html.fromstring(page.content)\n",
    "\n",
    "links = tree.xpath('//td[@class=\"titleColumn\"]/a')\n",
    "\n",
    "links = links[0:10]\n",
    "\n",
    "for link in links:\n",
    "    title = link.text\n",
    "    cast = ''\n",
    "    href = ''\n",
    "    if 'title' in link.attrib:\n",
    "        cast = link.attrib['title']    \n",
    "    if 'href' in link.attrib:\n",
    "        href = link.attrib['href']\n",
    "        href = 'http://www.imdb.com/' + href\n",
    "    print title\n",
    "    print 'Cast : ' + cast \n",
    "    print 'Link : '+ href\n",
    "    \n",
    "    # buka detail halaman\n",
    "    detail_page = requests.get(href)\n",
    "    detail_tree = html.fromstring(detail_page.content)\n",
    "    \n",
    "    description = detail_tree.xpath('//p[@itemprop=\"description\"]/text()')\n",
    "    print description\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Final Project\n",
    "\n",
    "NRP-Nama, NRP-Nama, NRP-Nama, Judul & Deskripsi Singkat\n",
    "\n",
    "121110531-Muhammad Ashpihani, 121110532-Erwin Eka, Pengklasifikasian berita olahraga (MotoGP & F1) menggunakan KNN, Input program berupa file txt, proses, pembandingan antara berita sample dan file txt yang telah diinputkan. Program yang dibuat berbasis java GUI.\n",
    "\n",
    "121110538-Lalu Haryadi Guni, Pengklasifikasian berita olahraga (bola & basket) menggunakan KNN, Input program berupa file txt, proses, pembandingan antara berita sample dan file txt yang telah diinputkan. Program yang dibuat berbasis ruby CLI.\n",
    "\n",
    "121110562-Benny Eka Atmojo, 131110666-Ade Sutiari, 131110642-Syntia W. Putri Listio, Pencarian Judul Manga dengan boolean indexing, pengumpulan data judul manga diambil menggunakan web scraping dari situs mangainn.com lalu untuk pencariannya menggunakan boolean indexing.\n",
    "\n",
    "121110506-ferry sanjaya, 121110511-Arief yuwono , 121110500-albert ferento , Pencarian dokumen dengan menggunakan Vector Space model, data diambil dari database input user berupa query\n",
    "\n",
    "121110536-Shinta Purnama Sari, 121110539-Eka Dewi Susanti, 141112003 Raudatul Jannah, pencarian judul lagu menggunakan boolean indexing berbasis web, program ini akan berdasarkan katagori\n",
    "\n",
    "131110645-Bulan Dewi Gulita, 131110623-Endah Laksmita P, 131110648-Niko Kelana Sandi, Pencarian Resep berdasarkan komposisi bahan menggunakan boolean retrieval, pencarian dilakukan pada database resep yang telah ada, program berbasis web.\n",
    "\n",
    "131110649 Hamdan Baharudin, 131110655 Kevin Yosua Leonardy, Pencarian Musik dengan boolean retrieval, pengumpulan data diambil menggunakan web scraping dari situs kat.cr\n",
    "\n",
    "121110517 Fitri Dayanti, 121110526 Ita Kumala Wardani, 121110534 Sendi Kurniawaty, pencarian kuliner Malang kategori Cafe menggunakan boolean indexing\n",
    "\n",
    "121110499 Mahartin Hendra S, 121110495 M. Zaidi Effendi, pencarian lowongan kerja di kabupaten malang (kabupatenmalang.go.id) dengan boolean indexing, pengumpuan data di ambil menggunakan web scraping.\n",
    "\n",
    "131110646 Leo Armanda Al Fadhillah, 131110619 Burhanuddin, 131110698 Satria Dwi Mahanani, Pencarian tipe motor berdasarkan spesifikasi menggunakan boolean retrival pada database yang telah ada. program berbasis web\n",
    "\n",
    "101110234 Moh. Haris Mabrur, 1111110444 Fachry Restu Pambudi, Pencarian Cerita Rakyat Indonesia berbasis web dengan menggunakan bolean indexing pada database yang telah ada\n",
    "\n",
    "101110222 Samuel Pusirumang Makahanap , 121110568 erwin kristanto, Pencarian topik dalam forum bebas dengan menggunakan boolean indexing.\n",
    "\n",
    "111110427 dimas lutfi f. pencarian profil member jkt48 beserta schedulenya berbasis bolean indexin dan web scraping\n",
    "\n",
    "Aji Fitriono 121110505, Dawang Mahendra 121110567, Dimas Aditya 121110598. Web Scrapping pencarian info cafe di Malang dan Surabaya menggunakan boolean indexing\n",
    "\n",
    "121110599 Andriansyah Dwi W, 121110597 Yosua Christian. Pencarian kata di dalam artikel dengan vector space model\n",
    "\n",
    "101110243 Fahrul Ekandy, 101110345 Anjang Wijaya. Pencarian Film Anime dengan boolean indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
